






new


async def download_NH_input(url, base_url, title, download, Collection_path):
    """Download and process NH legal statutes and store in MongoDB"""

    Collection_path = os.path.join(Collection_path, f"Title_{title}")
    if not os.path.exists(Collection_path):
        os.makedirs(Collection_path)

    # Fetch TOC List
    toc_list = await get_title_dict()

    if title:
        # Get title URL from fetch_title()
        title_url = toc_list.get(title, "")
        ack = await fetch_title(title, title_url)

        if not ack.get("chapters"):
            logger.error(f"ERROR: No chapters found for title {title}. URL might be incorrect")
            return None

        with connect_to_mongodb() as client:
            logging.info(f"Connected to {config['docdb']} database")
            db = client[config['docdb']]
            collection = db[config['collection_name']]

            # Create task ID
            query = {"taskId": {"$regex": "^NH"}}
            taskId = collection.count_documents(query) + 1
            taskId = f"NH{taskId}"
            logging.info(f"Generated Task ID: {taskId}")

            # Get current date
            formatted_date = datetime.now().strftime("%Y-%m-%d")
            createDate = download["createdDate"]
            if isinstance(createDate, date):
                createDate = createDate.isoformat()

            fileDetail = []

            for chapter_name, chapter_url in ack["chapters"].items():
                chapter_data = await fetch_chapter(chapter_name, chapter_url, ack["title_name"], ack["directory"])

                if chapter_data:
                    # Generate structured filename (TitleNumber_ChapterNumber.xml)
                    chapter_match = re.search(r'CHAPTER (\d+[A-Z\-]*)', chapter_name, re.IGNORECASE)
                    chapter_number = chapter_match.group(1) if chapter_match else "Unknown"
                    filename = f"{title}_{chapter_number}.xml"
                    file_path = os.path.join(Collection_path, filename)

                    # Save as XML file
                    with open(file_path, "w", encoding="utf-8") as file:
                        json.dump(chapter_data, file, indent=4)

                    details = {
                        "Name": filename,
                        "collection": "true",
                        "common_conversion": "",
                        "mncr_conversion": "",
                        "meta": "",
                        "toc": "",
                        "type": config["NH_seclevel"],
                        "titleName": chapter_name,
                        "normCite": ""
                    }
                    fileDetail.append(details)

            # Insert title details into MongoDB
            title_details = {
                "jX": download["jX"],
                "createdBy": download["createdBy"],
                "createdDate": createDate,
                "titleNo": title,
                "titleName": download["Title"],
                "downloadDate": formatted_date,
                "totalFiles": len(ack),
                "fileDetail": fileDetail,
                "finalStage": "Conversion",
                "finalStatus": "In Progress",
                "taskId": taskId
            }
            collection.insert_one(title_details)
            logging.info(f"Title {title} inserted into {config['collection_name']} collection")

        client.close()
        return ack

    else:
        for title_num, _ in toc_list.items():
            title_url = toc_list.get(title_num, "")
            message = await fetch_title(title_num, title_url)
        return message




async def download_NH_input(url, base_url, title, download, Collection_path):
    """Download and process NH legal statutes and store in MongoDB"""

    Collection_path = os.path.join(Collection_path, f"Title_{title}")
    if not os.path.exists(Collection_path):
        os.makedirs(Collection_path)

    # Fetch TOC List
    toc_list = await get_title_dict()

    if title:
        title_url = toc_list.get(title, "")
        ack = await fetch_title(title, title_url)

        if not ack.get("chapters"):
            logger.error(f"ERROR: No chapters found for title {title}. URL might be incorrect")
            return None

        with connect_to_mongodb() as client:
            logging.info(f"Connected to {config['docdb']} database")
            db = client[config['docdb']]
            collection = db[config['collection_name']]

            # Check if the title exists in MongoDB
            if (book := collection.find_one({"jx": "NH", "titleNo": title, "isDeleted": {"$exists": False}})) is not None:
                task_id = book["taskId"]
                query = {"taskId": task_id}
                file_details = []

                for chapter_name, chapter_url in ack["chapters"].items():
                    chapter_data = await fetch_chapter(chapter_name, chapter_url, ack["title_name"], ack["directory"])

                    if chapter_data:
                        # Extract Roman numeral title
                        title_number = title.strip()

                        # Extract chapter number
                        chapter_match = re.search(r'CHAPTER (\d+[A-Z\-]*)', chapter_name, re.IGNORECASE)
                        chapter_number = chapter_match.group(1) if chapter_match else "Unknown"

                        # Generate filename (e.g., III_201.xml, III_201_A.xml)
                        filename = f"{title_number}_{chapter_number}.xml"
                        file_path = os.path.join(Collection_path, filename)

                        # Save file in XML format
                        with open(file_path, "w", encoding="utf-8") as file:
                            json.dump(chapter_data, file, indent=4)

                        details = {
                            "Name": filename,
                            "collection": "true",
                            "common_conversion": "",
                            "mncr_conversion": "",
                            "meta": "",
                            "toc": "",
                            "type": config["NH_seclevel"],
                            "titleName": chapter_name,
                            "normCite": ""
                        }
                        file_details.append(details)

                # Update MongoDB records
                collection.update_one(query, {"$set": {"fileDetail": file_details}})
                collection.update_one(query, {"$set": {"totalFiles": len(file_details), "finalStage": "Conversion"}})

                logging.info(f"Title {title} inserted into {config['collection_name']} collection")

            client.close()
            logging.info(f"Title {title} Conversion in progress")

            # Send conversion request
            conv_url = config["convert_request"]
            payload = json.dumps({
                "data": {
                    "jx": "NH",
                    "createdBy": "",
                    "createdDate": datetime.now().strftime("%Y-%m-%d"),
                    "firstLeveno": f"{title}",
                    "firstLeveltitle": ""
                },
                "additionalParam": {
                    "convRawXm1": "yes",
                    "convMncrXm1": "string"
                }
            }, indent=4)

            headers = {"Content-Type": "application/json"}
            logging.info(f"Payload {payload}")

            try:
                async with aiohttp.ClientSession() as session:
                    async with session.post(conv_url, headers=headers, data=payload) as response:
                        request_resp = await response.text()
                        logging.info(f"Conversion request sent for {title}")
            except Exception as e:
                logging.error(f"Conversion request failed for {title} {e}")

        return ack

    else:
        for title_num in toc_list.keys():
            title_url = toc_list.get(title_num, "")
            message = await fetch_title(title_num, title_url)
        return message

import os
import aiohttp
import asyncio
import nest_asyncio
import json
import logging
import re
import xml.etree.ElementTree as ET
from datetime import datetime, date
from bs4 import BeautifulSoup
from pyppeteer import launch
from Utilities.logging_config import setup_logging
from Utilities.DB_connection import connect_to_mongodb
from Utilities.config import configureation

# Load configuration
config = configureation()
nest_asyncio.apply()

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

HEADERS = {'User-Agent': 'Mozilla/5.0'}

async def get_content(url):
    """Fetch content asynchronously using Pyppeteer (handles JavaScript rendering)"""
    try:
        browser = await launch(headless=True, args=['--no-sandbox'])
        page = await browser.newPage()
        await page.goto(url, {'waitUntil': 'networkidle2'})
        content = await page.content()
        await browser.close()
        return BeautifulSoup(content, 'html.parser')
    except Exception as e:
        logger.error(f"Failed to fetch content from {url}: {e}")
        return None

async def get_title_dict(url):
    """Fetch title dictionary from the main page dynamically"""
    soup = await get_content(url)
    if not soup:
        return {}

    title_links = soup.find_all('a', href=True)
    return {
        a.text.strip(): url + a['href'].replace("../", "NHTOC/")
        for a in title_links if 'NHTOC/' in a['href']
    }

async def fetch_title(title_name, title_url, base_url):
    """Fetch and process each title"""
    logger.info(f"Downloading title: {title_name}")
    title_soup = await get_content(title_url)
    if not title_soup:
        return {}

    chapter_links = title_soup.find_all('a', href=True)
    chapter_urls = {
        a.text.strip(): base_url + "NHTOC/" + a['href']
        for a in chapter_links if 'NHTOC-' in a['href']
    }

    return {"title_name": title_name, "title_url": title_url, "chapters": chapter_urls}

async def fetch_chapter(chapter_name, chapter_url, title_name):
    """Fetch and process each chapter"""
    logger.info(f"Fetching chapter: {chapter_name}")
    chapter_soup = await get_content(chapter_url)
    if not chapter_soup:
        return None

    body_tag = chapter_soup.find('body')
    if not body_tag:
        logger.warning(f"Skipping {chapter_name} - No <body> tag found.")
        return None

    section_link_tag = next(
        (a_tag for h2_tag in body_tag.find_all('h2') if (a_tag := h2_tag.find('a', href=True)) and "../" in a_tag["href"]), 
        None
    )

    if not section_link_tag:
        logger.warning(f"Skipping {chapter_name} - No valid section link found.")
        return None

    section_url = section_link_tag['href'].replace('../', '')
    return await fetch_section(section_url, chapter_name, title_name)

async def fetch_section(section_url, chapter_name, title_name):
    """Fetch section data and return formatted content for MongoDB storage"""
    section_soup = await get_content(section_url)
    if not section_soup:
        return None

    meta_tag = section_soup.find('meta', {'name': 'chapter'})
    if meta_tag:
        chapter_name = meta_tag['content'].strip()

    chapter_content = {
        "title_name": title_name,
        "chapter_name": chapter_name,
        "sections": []
    }

    sections = section_soup.find_all('center')
    seen_sections = set()

    for section in sections:
        section_title_tag = section.find_next('b')
        if section_title_tag:
            section_text = section_title_tag.get_text(strip=True)

            if section_text in seen_sections:
                continue
            seen_sections.add(section_text)

            section_content = section.find_next('codesect')
            section_content_text = section_content.get_text("\n").strip() if section_content else "No content available"

            formatted_content = [
                {"type": "h3", "text": line.strip()} if re.match(r"^?[a-z0-9]+?\.", line.strip()) else {"type": "p", "text": line.strip()}
                for line in section_content_text.split("\n") if line.strip()
            ]

            chapter_content["sections"].append({
                "section_title": section_text,
                "content": formatted_content
            })

    return chapter_content if chapter_content["sections"] else None

async def download_NH_input(url, base_url, title, download, collection_path):
    """Download and process NH legal statutes and store in MongoDB"""

    collection_path = os.path.join(collection_path, f"Title_{title}")
    if not os.path.exists(collection_path):
        os.makedirs(collection_path)

    toc_list = await get_title_dict(url)

    if title:
        title_url = f"{base_url}NHTOC/nhtoc_ch{title}.htm"
        ack = await fetch_title(title, title_url, base_url)

        with connect_to_mongodb() as client:
            logging.info(f"Connected to {config['docdb']} database")
            db = client[config['docdb']]
            collection = db[config['collection_name']]

            if (book := collection.find_one({"jx": 'NH', "titleNo": title, "isDeleted": {"$exists": False}})) is not None:
                task_id = book["taskId"]
                query = {"taskId": task_id}
                file_details = []

                for chapter_name, chapter_url in ack["chapters"].items():
                    chapter_data = await fetch_chapter(chapter_name, chapter_url, ack["title_name"])
                    
                    if chapter_data:
                        filename = f"title_{chapter_name}.xml"

                        details = {
                            "Name": filename,
                            "collection": "true",
                            "common_conversion": "",
                            "mncr_conversion": "",
                            "meta": "",
                            "toc": "",
                            "type": config['NH_seclevel'],
                            "titleName": chapter_name,
                            "normCite": ""
                        }
                        file_details.append(details)

                        file_path = os.path.join(collection_path, filename)
                        with open(file_path, "w", encoding="utf-8") as file:
                            json.dump(chapter_data, file, indent=4)

                collection.update_one(query, {"$set": {"fileDetail": file_details}})
                collection.update_one(query, {"$set": {"totalFiles": len(file_details), "finalStage": "Conversion"}})

                logging.info(f"Title {title} inserted into {config['collection_name']} collection")

            client.close()
            logging.info(f"Title {title} Conversion in progress")

async def toc_NH(url):
    toc_list = await get_title_dict(url)
    root = ET.Element("hierarchy")

    for key, val in toc_list.items():
        title_number = key.split(':')[0].strip().replace("TITLE", "").strip()
        title_name = key.split(':')[1].strip()

        child = ET.Element("chunk")
        child.set("label", title_number)
        child.set("title", title_name)
        root.append(child)

    return ET.tostring(root, encoding="unicode")
